To run this RNN example, start a command prompt in this directory and enter:

python recurrent_network.py

and press <RETURN>

Output will look something like:

2018-06-16 12:34:16.029272: I T:\src\github\tensorflow\tensorflow\core\platform\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
Step 1, Minibatch Loss= 2.7860, Training Accuracy= 0.133
Step 200, Minibatch Loss= 2.0856, Training Accuracy= 0.312
Step 400, Minibatch Loss= 1.8684, Training Accuracy= 0.430
Step 600, Minibatch Loss= 1.7528, Training Accuracy= 0.453
Step 800, Minibatch Loss= 1.7717, Training Accuracy= 0.445
Step 1000, Minibatch Loss= 1.4616, Training Accuracy= 0.578
Step 1200, Minibatch Loss= 1.4604, Training Accuracy= 0.633
Step 1400, Minibatch Loss= 1.4900, Training Accuracy= 0.508
Step 1600, Minibatch Loss= 1.3401, Training Accuracy= 0.594
Step 1800, Minibatch Loss= 1.4048, Training Accuracy= 0.594
Step 2000, Minibatch Loss= 1.2466, Training Accuracy= 0.609
Step 2200, Minibatch Loss= 1.1609, Training Accuracy= 0.727
Step 2400, Minibatch Loss= 1.0692, Training Accuracy= 0.688
Step 2600, Minibatch Loss= 1.0857, Training Accuracy= 0.688
Step 2800, Minibatch Loss= 1.1394, Training Accuracy= 0.695
Step 3000, Minibatch Loss= 1.0510, Training Accuracy= 0.664
Step 3200, Minibatch Loss= 0.8538, Training Accuracy= 0.750
Step 3400, Minibatch Loss= 1.0630, Training Accuracy= 0.703
Step 3600, Minibatch Loss= 0.8613, Training Accuracy= 0.727
Step 3800, Minibatch Loss= 1.0610, Training Accuracy= 0.648
Step 4000, Minibatch Loss= 0.9064, Training Accuracy= 0.742
Step 4200, Minibatch Loss= 0.7667, Training Accuracy= 0.789
Step 4400, Minibatch Loss= 0.8161, Training Accuracy= 0.758
Step 4600, Minibatch Loss= 0.8102, Training Accuracy= 0.766
Step 4800, Minibatch Loss= 0.7454, Training Accuracy= 0.758
Step 5000, Minibatch Loss= 0.7146, Training Accuracy= 0.758
Step 5200, Minibatch Loss= 0.7319, Training Accuracy= 0.750
Step 5400, Minibatch Loss= 0.7324, Training Accuracy= 0.742
Step 5600, Minibatch Loss= 0.6144, Training Accuracy= 0.805
Step 5800, Minibatch Loss= 0.7956, Training Accuracy= 0.734
Step 6000, Minibatch Loss= 0.7727, Training Accuracy= 0.766
Step 6200, Minibatch Loss= 0.5747, Training Accuracy= 0.828
Step 6400, Minibatch Loss= 0.5088, Training Accuracy= 0.844
Step 6600, Minibatch Loss= 0.6985, Training Accuracy= 0.797
Step 6800, Minibatch Loss= 0.6025, Training Accuracy= 0.781
Step 7000, Minibatch Loss= 0.5578, Training Accuracy= 0.812
Step 7200, Minibatch Loss= 0.5049, Training Accuracy= 0.820
Step 7400, Minibatch Loss= 0.6081, Training Accuracy= 0.773
Step 7600, Minibatch Loss= 0.6100, Training Accuracy= 0.852
Step 7800, Minibatch Loss= 0.6066, Training Accuracy= 0.781
Step 8000, Minibatch Loss= 0.5314, Training Accuracy= 0.781
Step 8200, Minibatch Loss= 0.4879, Training Accuracy= 0.867
Step 8400, Minibatch Loss= 0.4194, Training Accuracy= 0.883
Step 8600, Minibatch Loss= 0.5622, Training Accuracy= 0.820
Step 8800, Minibatch Loss= 0.5239, Training Accuracy= 0.820
Step 9000, Minibatch Loss= 0.3995, Training Accuracy= 0.891
Step 9200, Minibatch Loss= 0.3970, Training Accuracy= 0.867
Step 9400, Minibatch Loss= 0.5776, Training Accuracy= 0.805
Step 9600, Minibatch Loss= 0.5368, Training Accuracy= 0.844
Step 9800, Minibatch Loss= 0.4378, Training Accuracy= 0.867
Step 10000, Minibatch Loss= 0.4057, Training Accuracy= 0.852
Optimization Finished!
Testing Accuracy: 0.875